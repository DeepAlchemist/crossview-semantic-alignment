# FashionIQ data nums: 18000

includes:
- configs/models/composition/defaults.yaml

model_config:
  simple_composition:
    image_encoder:
      type: vqvae_encoder
      params:
        pretrained_path: ${env.data_dir}/pretrained_models/vqvae_ema_pp_224_encoder.pth
        resolution: 224
        num_tokens: 1024
        codebook_dim: 256
        attn_resolutions: [14]
        hidden_dim: 128
        in_channels: 3
        ch_mult: [1, 1, 2, 2, 4]
        num_res_blocks: 2
        dropout: 0
        z_channels: 256
        double_z: false

    image_projection:
      type: identity
      params:
        in_dim: 512
        out_dim: 512

dataset_config:
  fashioniq:
      processors:
        train_image_processor:
          type: torchvision_transforms
          params:
            transforms:
              - type: RandomResizedCrop
                params:
                  size: [224, 224]
                  scale: [0.8, 1.0]
                  ratio: [0.75, 1.3]
              - RandomHorizontalFlip
              - ToTensor
              - type: Normalize
                params:
                  mean: [0.5, 0.5, 0.5]
                  std: [0.5, 0.5, 0.5]
        eval_image_processor:
          type: torchvision_transforms
          params:
            transforms:
              - type: Resize
                params:
                  size: [224, 224]
              - ToTensor
              - type: Normalize
                params:
                  mean: [0.5, 0.5, 0.5]
                  std: [0.5, 0.5, 0.5]

scheduler:
  type: multi_step
  params:
    use_warmup: true
    lr_steps:
    - 16860
    - 28100
    lr_ratio: 0.1
    warmup_iterations: 2810
    warmup_factor: 0.25

optimizer:
  type: adam_w
  params:
    lr: 2e-4
    eps: 1e-8

evaluation:
  metrics:
    - r@k_fashioniq

training:
  experiment_name: simple_composition_fashioniq_vqvae
  batch_size: 32
  lr_scheduler: true
  max_updates: 44960
  log_interval: 10
  checkpoint_interval: 5620
  evaluation_interval: 562
  early_stop:
    criteria: fashioniq/r@k_fashioniq/avg
    minimize: false
  wandb:
    enabled: true

run_type: train_val
